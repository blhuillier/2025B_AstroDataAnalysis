{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUYsKMp7h4w3"
      },
      "source": [
        "Among the following models, which model fits the Pantheon supernovae compilation better? why?\n",
        "$\\Lambda$CDM, Flat $\\Lambda$CDM, $w$CDM, Flat $w$CDM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "given-charge",
        "outputId": "81b5783c-ffb7-4816-b7d9-6110a0ee13b2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from astropy.cosmology import FlatLambdaCDM, LambdaCDM, wCDM,FlatwCDM\n",
        "from scipy import optimize\n",
        "import pandas as pd\n",
        "\n",
        "# These packages are not installed by default on Google Colab, we may need to\n",
        "# install them\n",
        "# I am using try/except so that we only install them if they're not already\n",
        "# installed:\n",
        "try:\n",
        "   import emcee\n",
        "except:\n",
        "  # emcee not installed, install it and import\n",
        "  !pip install emcee\n",
        "  import emcee\n",
        "# same for corner:\n",
        "try:\n",
        "  import corner\n",
        "except:\n",
        "  !pip install corner\n",
        "  import corner\n",
        "  \n",
        "try:\n",
        "  import dynesty\n",
        "except:\n",
        "  !pip install dynesty\n",
        "  import dynesty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "models = [\"FlatLCDM\",\"LCDM\",'FlatwCDM','wCDM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "continuing-berry"
      },
      "outputs": [],
      "source": [
        "z, mB, dmB = np.genfromtxt(\"https://raw.githubusercontent.com/dscolnic/Pantheon/master/lcparam_full_long.txt\", skip_header=0, usecols=(1, 4, 5), unpack=True)\n",
        "Nsn = len(z)\n",
        "Csys = np.genfromtxt(\"https://raw.githubusercontent.com/dscolnic/Pantheon/master/sys_full_long.txt\", skip_header=1).reshape((Nsn,Nsn))\n",
        "Cinv = np.linalg.inv(Csys + np.diag(dmB**2))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-Czsq9FGlMX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# creating a structured array:\n",
        "data = np.zeros(Nsn,dtype=[('z',float),('mB',float),('dmB',float)])\n",
        "data['z'] = z\n",
        "data['mB'] = mB\n",
        "data['dmB'] = dmB\n",
        "\n",
        "# creating a dataframe to save my results\n",
        "df = pd.DataFrame(columns=['Model','AIC','BIC','DIC','chi2min','chi2min/dof'])\n",
        "df['Model'] = models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7gTTYNHiS8T"
      },
      "outputs": [],
      "source": [
        "# Define my residual function (cost function):\n",
        "\n",
        "def residuals(params,model,data):\n",
        "  '''return residuals\n",
        "\n",
        "  order: Om0, Ode0, w,Mb\n",
        "  '''\n",
        "  assert model in [0,1,2,3], 'error, model={} unknown'.format(model)\n",
        "  H0 = 70.\n",
        "  if model == 0:\n",
        "    Om0,MB = params\n",
        "    cosmo = FlatLambdaCDM(Om0=Om0,H0=H0)\n",
        "  elif model == 1:\n",
        "    # LCDM:\n",
        "    Om0,Ode0,MB = params\n",
        "    cosmo = LambdaCDM(Om0=Om0,Ode0=Ode0,H0=H0)\n",
        "  elif model == 2:\n",
        "    # flat wCDM\n",
        "    Om0,w,MB = params\n",
        "    cosmo = FlatwCDM(Om0=Om0,w0=w,H0=H0)\n",
        "  elif model == 3:\n",
        "    Om0,Ode0,w,MB = params\n",
        "    cosmo = wCDM(Om0=Om0,Ode0=Ode0,w0=w,H0=H0)\n",
        "  dy = cosmo.distmod(data['z']).value - (data['mB'] - MB )\n",
        "  chi2 = dy.T @ Cinv @ dy\n",
        "  return chi2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrXmsaCLicJ8"
      },
      "source": [
        "## 1. Calculate AIC and BIC\n",
        "\n",
        "Minimize chi2 = Maximum Likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z939tIduinPz",
        "outputId": "2c8e598c-4c5d-4b02-b086-b55353db59e2"
      },
      "outputs": [],
      "source": [
        "# minimizing chi2 = max likelihood\n",
        "\n",
        "\n",
        "Nparams = [2,3,3,4]\n",
        "bounds = {}\n",
        "bounds[0] = ((0,1),(-25,-15))\n",
        "bounds[1] = ((0,1),(0,1),(-25,-15))\n",
        "bounds[2] = ((0,1),(-2,0),(-25,-15))\n",
        "bounds[3] = ((0,1),(0,1),(-2,0),(-25,-15))\n",
        "thetahat = {}\n",
        "for model in range(4):\n",
        "  print (72*\"=\")\n",
        "  print(\" Model: {}\".format(model))\n",
        "  res = optimize.differential_evolution(residuals,bounds=bounds[model],args=(model,data))\n",
        "  # x0 = np.zeros(Nparams[model])\n",
        "  # print (x0,bounds[model],)\n",
        "  # res = optimize.minimize(residuals,x0,args=(model,data),bounds=bounds[model])\n",
        "  print (res)\n",
        "  thetahat[model] = res.x\n",
        "  chi2 = res.fun\n",
        "  nu = Nsn-Nparams[model]\n",
        "  print( \" chi2/nu = {}/{} = {}\".format(chi2,nu,chi2/nu))\n",
        "\n",
        "  ii = df['Model'] == models[model]\n",
        "  print (ii,df.loc[ii])\n",
        "  df.loc[ii,'AIC'] = chi2 + 2*Nparams[model]\n",
        "  df.loc[ii,'BIC'] = chi2 + Nparams[model] * np.log(Nsn)\n",
        "  df.loc[ii,'chi2min'] = chi2\n",
        "  df.loc[ii,'chi2min/dof'] = chi2/nu\n",
        "  print (df)\n",
        "  # print (\" AIC={}\".format(DIC))\n",
        "\n",
        "print (df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ7pWsTCvQRp"
      },
      "source": [
        "# Run MCMC to calculate the DIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvwuncSGsXUB"
      },
      "outputs": [],
      "source": [
        "# Define my priors:\n",
        "\n",
        "def lnpOm0(Om0):\n",
        "  if 0<Om0<1:\n",
        "    return 0\n",
        "  else:\n",
        "    return -np.inf\n",
        "\n",
        "\n",
        "def lnpMB(MB):\n",
        "  ''' Note: this is an unnormalized prior.\n",
        "  The correct normalization would be -np.log(Mb_Max-Mb_min) = np.log(1/(Mbmax-Mbmin))\n",
        "  '''\n",
        "  if -25<MB<-15:\n",
        "    return 0\n",
        "  else:\n",
        "    return -np.inf\n",
        "\n",
        "def lnpOde0(Ode0):\n",
        "  if 0<Ode0<1:\n",
        "    return 0\n",
        "  else:\n",
        "    return -np.inf\n",
        "\n",
        "def lnpw(ww):\n",
        "  if -2<ww<0:\n",
        "    return 0\n",
        "  else:\n",
        "    return -np.inf\n",
        "\n",
        "def lnprior(theta,model):\n",
        "  '''Returns the (unnormalized) prior'''\n",
        "  Om0 = theta[0]\n",
        "  MB = theta[-1]\n",
        "  lp = lnpOm0(Om0) + lnpMB(MB)\n",
        "  if model in [1,3]:\n",
        "    Ode0 = theta[1]\n",
        "    lp += lnpOde0(Ode0)\n",
        "  if model in [2,3]:\n",
        "    ww = theta[-2]\n",
        "    lp += lnpw(ww)\n",
        "  return lp\n",
        "\n",
        "def lnP(theta,model,data):\n",
        "  '''Calculate the log posterior\n",
        "  ln P(theta) = ln pi(theta) + ln L (theta)\n",
        "  Also return the log likelihood as a blob.\n",
        "  '''\n",
        "  # 1. Get the prior for the parameters theta\n",
        "  lp = lnprior(theta,model)\n",
        "\n",
        "  # are the parameters within the priors?\n",
        "  if np.isfinite (lp):\n",
        "    # Get the log likelihood\n",
        "    ll = -.5*residuals(theta,model,data)\n",
        "    return lp+ll,ll\n",
        "  else:\n",
        "    # my prior is zero so I don't need to calculate ln L,\n",
        "    # I just return ln pi = -inf\n",
        "    return lp,lp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwK2tP-kvYLI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjr2Bt1mvYpb"
      },
      "source": [
        "# Calculate the DIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avDxeT-8_vdD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# listDIC = {}\n",
        "# listDIC[2] =  1029.2951853008806\n",
        "# listDIC[0] = 1030.5038073377136\n",
        "\n",
        "def DIC (mysample,thetamean):\n",
        "  # ln L = -.5*residuals(theta,model,data)\n",
        "  ll = mysample.get_blobs(flat=True,thin=nthin,discard=nburn).mean()\n",
        "  # chi2(\\bar\\theta) = residuals = -2 ln L(\\hat\\theta)\n",
        "  return -4*ll  - residuals(thetamean,model,data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUKOglFgvanV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnY-SOtSvayy"
      },
      "source": [
        "# Ok, now we run everything:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kpfNY1mktd97",
        "outputId": "d0401650-0a26-4430-a9fd-dc2565ff3eeb"
      },
      "outputs": [],
      "source": [
        "samplers = {}\n",
        "\n",
        "# fLCDM\n",
        "model = 0\n",
        "nwalker = 12\n",
        "ndim = Nparams[model]\n",
        "niter = 2000\n",
        "\n",
        "theta0 = thetahat[model] + 1e-4 * np.random.randn(nwalker, ndim)\n",
        "nwalkers, ndim = theta0.shape\n",
        "\n",
        "samplers[model] = emcee.EnsembleSampler(nwalkers, ndim, lnP, args=(model,data))\n",
        "samplers[model].run_mcmc(theta0, niter, progress=True);\n",
        "\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
        "samples = samplers[model].get_chain()\n",
        "labels = [r\"$\\Omega_m$\", r\"M_B\",]\n",
        "for i in range(ndim):\n",
        "    ax = axes[i]\n",
        "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
        "    ax.set_xlim(0, len(samples))\n",
        "    ax.set_ylabel(labels[i])\n",
        "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
        "\n",
        "    ax.axvline(x=50)\n",
        "axes[-1].set_xlabel(\"step number\");\n",
        "\n",
        "\n",
        "# AutocorrelatioN:\n",
        "tau = samplers[model].get_autocorr_time()\n",
        "print(tau)\n",
        "nburn = 50\n",
        "nthin = 30\n",
        "\n",
        "\n",
        "flat_samples = samplers[model].get_chain(discard=nburn, thin=nthin, flat=True)\n",
        "print(flat_samples.shape)\n",
        "thetamean = flat_samples.mean(axis=0)\n",
        "print(thetamean)\n",
        "\n",
        "fig = corner.corner(\n",
        "    flat_samples, labels=labels, truth=thetahat\n",
        ");\n",
        "\n",
        "\n",
        "myDIC = DIC(samplers[model],thetamean)\n",
        "print (myDIC)\n",
        "df.loc[model,'DIC'] = myDIC\n",
        "print (df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "5MvHuPfPqFhu",
        "outputId": "91be5875-3c0c-4c04-b3d8-579b5f1420fe"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = corner.corner(\n",
        "    flat_samples, labels=labels, truth=thetahat\n",
        ");\n",
        "\n",
        "fig.savefig(\"lcdm.pdf\",dpi=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Cw3h0P9FvUt_",
        "outputId": "db6870d5-6f9b-4e1b-db4c-c5cc1ceb5581"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jik2CWj64SH4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKdJuCut5O1U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nXC9m6Ml5k6X",
        "outputId": "6adb6ef4-2c43-4361-a330-434dd1c4b9a5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# LCDM\n",
        "# initialize my MCMC:\n",
        "model = 1\n",
        "nwalker = 12\n",
        "ndim = Nparams[model]\n",
        "niter = 4000\n",
        "\n",
        "# initial condition:\n",
        "theta0 = thetahat[model] + 1e-4 * np.random.randn(nwalker, ndim)\n",
        "nwalkers, ndim = theta0.shape\n",
        "\n",
        "samplers[model] = emcee.EnsembleSampler(nwalkers, ndim, lnP, args=(model,data))\n",
        "samplers[model].run_mcmc(theta0, niter, progress=True);\n",
        "\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
        "samples = samplers[model].get_chain()\n",
        "labels = [r\"$\\Omega_m$\", r\"$\\Omega_\\Lambda$\" ,r\"$M_B$\"]\n",
        "for i in range(ndim):\n",
        "    ax = axes[i]\n",
        "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
        "    ax.set_xlim(0, len(samples))\n",
        "    ax.set_ylabel(labels[i])\n",
        "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
        "\n",
        "    ax.axvline(x=50)\n",
        "axes[-1].set_xlabel(\"step number\");\n",
        "\n",
        "# AutocorrelatioN:\n",
        "tau = samplers[model].get_autocorr_time()\n",
        "print(tau)\n",
        "nburn = 50 # remove the first nburn iterations\n",
        "nthin = 30 # remove every nthin iteration to remove the correlation\n",
        "\n",
        "flat_samples = samplers[model].get_chain(discard=nburn, thin=nthin, flat=True)\n",
        "print(flat_samples.shape)\n",
        "thetamean = flat_samples.mean(axis=0)\n",
        "print(thetamean)\n",
        "\n",
        "fig = corner.corner(\n",
        "    flat_samples, labels=labels, truth=thetahat\n",
        ");\n",
        "\n",
        "\n",
        "myDIC = DIC(samplers[model],thetamean)\n",
        "print (myDIC)\n",
        "df.loc[model,'DIC'] = myDIC\n",
        "print (df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TNIK8t8d8ZmP",
        "outputId": "9c16ab6c-f7c3-4fb2-9b9e-258b2623b5b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# flatwCDM\n",
        "model = 2\n",
        "nwalker = 12\n",
        "ndim = Nparams[model]\n",
        "niter = 8000\n",
        "\n",
        "theta0 = thetahat[model] + 1e-4 * np.random.randn(nwalker, ndim)\n",
        "nwalkers, ndim = theta0.shape\n",
        "\n",
        "samplers[model] = emcee.EnsembleSampler(nwalkers, ndim, lnP, args=(model,data))\n",
        "samplers[model].run_mcmc(theta0, niter, progress=True);\n",
        "\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
        "samples = samplers[model].get_chain()\n",
        "labels = [r\"$\\Omega_m$\", r\"$w$\" ,r\"$M_B$\"]\n",
        "for i in range(ndim):\n",
        "    ax = axes[i]\n",
        "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
        "    ax.set_xlim(0, len(samples))\n",
        "    ax.set_ylabel(labels[i])\n",
        "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
        "\n",
        "    ax.axvline(x=50)\n",
        "axes[-1].set_xlabel(\"step number\");\n",
        "\n",
        "# AutocorrelatioN:\n",
        "tau = samplers[model].get_autocorr_time()\n",
        "print(tau)\n",
        "nburn = 50\n",
        "nthin = 30\n",
        "\n",
        "flat_samples = samplers[model].get_chain(discard=nburn, thin=nthin, flat=True)\n",
        "print(flat_samples.shape)\n",
        "thetamean = flat_samples.mean(axis=0)\n",
        "print(thetamean)\n",
        "\n",
        "fig = corner.corner(\n",
        "    flat_samples, labels=labels, truth=thetahat\n",
        ");\n",
        "\n",
        "\n",
        "\n",
        "myDIC = DIC(samplers[model],thetamean)\n",
        "print (myDIC)\n",
        "df.loc[model,'DIC'] = myDIC\n",
        "print (df)\n",
        "# myDIC[model] = DIC(sampler,thetamean)\n",
        "# # {2: 1029.2951853008806}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FiPChj_AHK_",
        "outputId": "f23e16e1-6589-467b-8213-bd0d1377980a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# wCDM\n",
        "model = 3\n",
        "nwalker = 12\n",
        "ndim = Nparams[model]\n",
        "niter = 10000\n",
        "\n",
        "print (thetahat[model])\n",
        "theta0 = thetahat[model] + 1e-4 * np.random.randn(nwalker, ndim)\n",
        "nwalkers, ndim = theta0.shape\n",
        "\n",
        "samplers[model] = emcee.EnsembleSampler(nwalkers, ndim, lnP, args=(model,data))\n",
        "samplers[model].run_mcmc(theta0, niter, progress=True);\n",
        "\n",
        "\n",
        "\n",
        "# # AutocorrelatioN:\n",
        "# #tau = sampler.get_autocorr_time()\n",
        "# print(tau)\n",
        "# nburn = 50\n",
        "# nthin = 30\n",
        "\n",
        "# flat_samples = sampler.get_chain(discard=nburn, thin=nthin, flat=True)\n",
        "# print(flat_samples.shape)\n",
        "# thetamean = flat_samples.mean(axis=0)\n",
        "# print(thetamean)\n",
        "\n",
        "# fig = corner.corner(\n",
        "#     flat_samples, labels=labels, truth=thetahat\n",
        "# );\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "J_FpoCEGI9ug",
        "outputId": "3b3397ea-e498-4cc6-8cd7-8d6b5b54c6ed"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "samples = samplers[model].get_chain()\n",
        "print (samples.shape)\n",
        "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
        "labels = [r\"$\\Omega_m$\", r\"$\\Omega_\\Lambda$\", r\"$w$\" ,r\"$M_B$\"]\n",
        "for i,ax in enumerate(axes):\n",
        "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
        "    ax.set_xlim(0, len(samples))\n",
        "    ax.set_ylabel(labels[i])\n",
        "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
        "\n",
        "    ax.axvline(x=50)\n",
        "axes[-1].set_xlabel(\"step number\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1JosW5Zh8tym",
        "outputId": "3f340050-8f1f-41b9-de7b-f2dd9b457e4a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# AutocorrelatioN:\n",
        "#tau = sampler.get_autocorr_time()\n",
        "# print(tau)\n",
        "nburn = 50\n",
        "nthin = 30\n",
        "\n",
        "flat_samples = samplers[model].get_chain(discard=nburn, thin=nthin, flat=True)\n",
        "print(flat_samples.shape)\n",
        "thetamean = flat_samples.mean(axis=0)\n",
        "print(thetamean)\n",
        "\n",
        "fig = corner.corner(\n",
        "    flat_samples, labels=labels, truth=thetahat\n",
        ");\n",
        "\n",
        "\n",
        "\n",
        "myDIC = DIC(samplers[model],thetamean)\n",
        "print (myDIC)\n",
        "df.loc[model,'DIC'] = myDIC\n",
        "print (df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FZwC06-GQZt"
      },
      "source": [
        "# Dynesty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcTV5sscGRWs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGQ4aHcyGR4S",
        "outputId": "3290dd2b-a295-4c44-95d5-dc470c6c4cc4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNGEwZJqGWvV"
      },
      "outputs": [],
      "source": [
        "from dynesty import NestedSampler\n",
        "\n",
        "def loglike(theta,model,data):\n",
        "    return -.5*residuals(theta,model,data)\n",
        "\n",
        "def ptform(uu,model):\n",
        "    '''uu: (0,1)'''\n",
        "    theta = np.zeros_like(uu)\n",
        "    ii = 0\n",
        "    # Om0: \n",
        "    theta[ii] = uu[0]\n",
        "    ii+=1\n",
        "    if model in [1,3]:\n",
        "        # theta[1]: Ode0   in (0,1) \n",
        "        theta [ii] = uu[ii]\n",
        "        ii += 1\n",
        "    if model in [2,3]:\n",
        "        # theta[2]: ww in [-2,0]\n",
        "        theta[ii] = 2*uu[ii]-2\n",
        "    return theta\n",
        "\n",
        "# initialize our nested sampler\n",
        "# sampler = NestedSampler(loglike, ptform, ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# flcdm\n",
        "imodel = 0\n",
        "model = models[imodel]\n",
        "ndim = Nparams[imodel]\n",
        "sampler = NestedSampler(loglike, ptform, ndim,\n",
        "                        logl_args=(imodel,data),\n",
        "                        ptform_args=(imodel,)\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "sampler.run_nested()\n",
        "sresults = sampler.results\n",
        "\n",
        "# \"Dynamic\" nested sampling.\n",
        "dsampler = dynesty.DynamicNestedSampler(loglike, ptform, ndim)\n",
        "dsampler.run_nested()\n",
        "dresults = dsampler.results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "b3670894bbd1e7b192b3db5c0c2c572e2f3b5a02086c3c36a2774c74c259fbda"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
